{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c57a34f-64bc-4efb-8188-5ab24145702d",
   "metadata": {},
   "source": [
    "# Tests for Meeting on 13.11.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05310f48-b8b4-4702-a4a7-e53f5a0f32a1",
   "metadata": {},
   "source": [
    "## Basic functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a576e9-25f6-4b1f-8757-1935cea28ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c835af-8898-4578-ad19-cc52f03c2217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fasta(filename):\n",
    "    fasta_sequences = SeqIO.parse(open(filename),'fasta')\n",
    "    seqs = []\n",
    "    for fasta in fasta_sequences:\n",
    "        name, sequence = fasta.id, str(fasta.seq)\n",
    "        seqs.append(sequence)\n",
    "    #print(len(sequence))\n",
    "    for seq in seqs:\n",
    "        print(len(seq))\n",
    "    return seqs\n",
    "\n",
    "\n",
    "def write_fasta(seqs, filename):\n",
    "    with open(filename, \"w\") as file:\n",
    "        for i in range(len(seqs)-1):\n",
    "            line = parse_num_to_nuc(seqs[i])\n",
    "            strline = \"\".join(line) + \"\\n\"\n",
    "            file.write(\"> \" + str(i) + \"\\n\" + strline)\n",
    "        \n",
    "        #print(line)\n",
    "        file.write(\">last\\n\")\n",
    "        line = parse_num_to_nuc(seqs[len(seqs)-1])\n",
    "        file.write(\"\".join(line))\n",
    "\n",
    "\n",
    "def get_reads_from(seq, read_len=200, coverage=5):\n",
    "    L = len(seq)\n",
    "    read_amt = int(L/read_len * coverage)\n",
    "    reads = []\n",
    "    for _ in range(read_amt):\n",
    "        start = np.random.randint(0,L-read_len)\n",
    "        read = seq[start:start+read_len]\n",
    "        read = parse_nucleotides(read, caps=True)\n",
    "        reads.append(read)\n",
    "    return reads\n",
    "\n",
    "def get_even_reads_from(seq, read_len=250, amt=6):\n",
    "    step_size = int(len(seq)/(2*read_len))\n",
    "    reads = []\n",
    "    reads.append(seq)\n",
    "    i=0\n",
    "    while i <= len(seq)-read_len:\n",
    "        reads.append(seq[i:i+read_len])\n",
    "        randomness = np.random.randint(-2,2)\n",
    "        i += int(read_len / amt) + randomness\n",
    "    reads.append(seq[len(seq)-read_len:len(seq)])\n",
    "    return reads\n",
    "\n",
    "\n",
    "def parse_nucleotides(sequence, caps=False):\n",
    "    new_seq = []\n",
    "    if caps:\n",
    "        map_to_vals = {\"A\": 1, \"C\": 2, \"G\": 3, \"T\":4}\n",
    "    else:\n",
    "        map_to_vals = {\"a\": 1, \"c\": 2, \"g\": 3, \"t\":4}\n",
    "    for symbol in sequence:\n",
    "        new_seq.append(map_to_vals[symbol])\n",
    "        \n",
    "    return new_seq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847dff2b-6b12-48b0-b8d1-e8acbf700961",
   "metadata": {},
   "source": [
    "## Profile correction algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7cf494a-582f-47a3-930b-b16edf9e5977",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_maxcount(pos, seqs_kmers, spaced_kmer_profile, target):\n",
    "    #target = seqs[seq_to_investigate]\n",
    "    f = len(spaced_kmer_profile)\n",
    "    counts_i = []\n",
    "    indexes = []\n",
    "    len_loop = min(f-1, pos)\n",
    "    start = pos-len_loop\n",
    "    end = pos+1\n",
    "    for i in range(start, end):\n",
    "        if spaced_kmer_profile[pos-i] != 1:\n",
    "            counts_i.append(0)\n",
    "            indexes.append(-1)\n",
    "            continue\n",
    "        \n",
    "        # Extract k mers starting at selected position\n",
    "        spaced_kmer = target[i : i+f] * spaced_kmer_profile\n",
    "        spaced_kmer = spaced_kmer[spaced_kmer != 0]\n",
    "        s = ''.join(str(x) for x in spaced_kmer)\n",
    "        counts_i.append(seqs_kmers[s])\n",
    "        indexes.append(i)\n",
    "    \n",
    "    return max(counts_i), indexes[np.argmax(counts_i)]\n",
    "\n",
    "\n",
    "def correct_counts(maxed_counts, maxed_count_indices, target_sequence, start_end_posis, seqs, diff_profile, kmer_profile):\n",
    "    f = len(kmer_profile)\n",
    "    correction_artifact = []\n",
    "    last_correction = 0 \n",
    "    # When corrections are necessary they are written into the maxed_counts array\n",
    "    for i in range(1,len(maxed_count_indices)):\n",
    "        # Make sure we have a change position on our hands.\n",
    "        if maxed_counts[i] != maxed_counts[i-1]: \n",
    "            start_sum_at = last_correction\n",
    "            end_sum_at = maxed_count_indices[i]+1\n",
    "            \n",
    "            if start_sum_at <= end_sum_at:\n",
    "                correction = sum(start_end_posis[start_sum_at:end_sum_at])\n",
    "            else:\n",
    "                correction = -sum(start_end_posis[end_sum_at:start_sum_at])\n",
    "                \n",
    "            last_correction = maxed_count_indices[i] + 1\n",
    "            diff_profile[i-1] += correction\n",
    "            correction_artifact.append([correction, (start_sum_at, end_sum_at), start_end_posis[start_sum_at:end_sum_at]])\n",
    "\n",
    "    return diff_profile, correction_artifact\n",
    "\n",
    "\n",
    "\n",
    "def get_correction_profile(target, seqs, overlap_size, start_dict, end_dict):\n",
    "    corr_profile = [0 for i in range(len(target)-overlap_size+2)]\n",
    "    #corr_profile[0] = -1\n",
    "    for i in range(len(target)-overlap_size):\n",
    "        #\n",
    "        #if i == 0:\n",
    "            # Note that this whole check is necessary because our target sequence, i.e. the read we are investigating at the moment\n",
    "            # also starts at the beginning and would thus be added to the count profile. We anticipate this by increasing the correction\n",
    "            # profile at this point to one s.t. the loop below can reduce it to zero in the first step if just our sequence starts there.\n",
    "            # If another sequence starts here, then the loop below will reduce the correction profile below zero\n",
    "            #corr_profile[0] = 1\n",
    "        start_snippet = ''.join(str(x) for x in target[i : i+overlap_size])      \n",
    "        if start_snippet in start_dict:\n",
    "            #print(target_snippet)\n",
    "            #print(se_dict[target_snippet])\n",
    "            corr_profile[i] -= start_dict[start_snippet]\n",
    "\n",
    "    for i in range(overlap_size, len(target)+1):\n",
    "        end_snippet = ''.join(str(x) for x in target[i-overlap_size : i])\n",
    "        if end_snippet in end_dict:\n",
    "            corr_profile[i-overlap_size+1] += end_dict[end_snippet]\n",
    "    \n",
    "        \n",
    "    corr_profile[0]=0\n",
    "    return corr_profile\n",
    "\n",
    "\n",
    "\n",
    "def correct_diff_profile(filename, str_profile, seq_to_investigate, data=[]):\n",
    "    seqs = []\n",
    "    if data:\n",
    "        for read in data:\n",
    "            sequence_chars = [val for val in read]\n",
    "            sequence = parse_nucleotides(sequence_chars)\n",
    "            seqs.append(np.array(sequence))\n",
    "    else:\n",
    "        with open(filename) as file_in:\n",
    "            for line in file_in:\n",
    "                newline = line.rstrip('\\n')\n",
    "                sequence_chars = [char for char in newline]\n",
    "                sequence = parse_nucleotides(sequence_chars)\n",
    "                seqs.append(np.array(sequence))\n",
    "    \n",
    "    profile = [int(character) for character in str_profile]\n",
    "    k = sum(profile)\n",
    "    f = len(profile)\n",
    "    \n",
    "    # Turn into np arrays for componentwise multiplication\n",
    "    profile = np.array(profile)\n",
    "    \n",
    "    # Count occurence of spaced k-mers\n",
    "    starts = {}\n",
    "    ends = {}\n",
    "    seqs_kmers = {}\n",
    "    for sequence in seqs:\n",
    "        for i in range(len(sequence) - f):\n",
    "            parsed_seq = parse_nucleotides(sequence)\n",
    "            spaced_kmer = parsed_seq[i:i+f] * profile\n",
    "            spaced_kmer = spaced_kmer[spaced_kmer != 0]\n",
    "            s = ''.join(str(x) for x in spaced_kmer)\n",
    "            if s not in seqs_kmers:\n",
    "                seqs_kmers[s] = 1\n",
    "            else:\n",
    "                seqs_kmers[s] += 1\n",
    "\n",
    "            if i == 0 or i == len(sequence)-f-1:\n",
    "                solid_kmer = sequence[i:i+f]\n",
    "                s2 = ''.join(str(x) for x in solid_kmer)\n",
    "                addon = 0\n",
    "                if i == 0:\n",
    "                    starts[s2] = starts.get(s2, 0) + 1\n",
    "                else: \n",
    "                    ends[s2] = ends.get(s2, 0) + 1\n",
    "    \n",
    "    # Get maxcounts from counts\n",
    "    target = seqs[seq_to_investigate]\n",
    "    xpoints = np.array([i for i in range(len(target) - f)])\n",
    "    max_counts = []\n",
    "    max_count_indices = []\n",
    "    for i in range(len(xpoints)):\n",
    "        maxp, argmaxp = get_maxcount(i, seqs, seqs_kmers, profile, seq_to_investigate=seq_to_investigate)\n",
    "        max_counts.append(maxp)\n",
    "        max_count_indices.append(argmaxp)\n",
    "    #print(max_count_indices)\n",
    "    # Get correction profile:\n",
    "    start_end_posis = get_correction_profile(target, seqs, f, starts, ends)\n",
    "    #print(start_end_posis)\n",
    "    #print(start_end_posis)\n",
    "    #print(max_count_indices)\n",
    "    \n",
    "    # Get diff profile:\n",
    "    pre_corr_diff_profile = [max_counts[j] - max_counts[j-1] for j in range(1,len(max_counts))]\n",
    "    \n",
    "    # Apply correction strategy\n",
    "    ypoints, correction_artifact = correct_counts(max_counts, max_count_indices, target, start_end_posis, seqs, pre_corr_diff_profile.copy(), profile)\n",
    "    return xpoints[1:], ypoints, max_counts, start_end_posis, pre_corr_diff_profile, correction_artifact, max_count_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0730d78-17fe-47e7-affb-8607bf01fd00",
   "metadata": {},
   "source": [
    "## Writing max count profiles to a file in a format that can be loaded into genome browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec055899-9aba-4470-bc9e-f6600e38d049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3390388\n",
      "757205\n"
     ]
    }
   ],
   "source": [
    "long_seqs = load_fasta(\"../data/Pseudoalteromonas_translucida_KMM_520_genomic.fasta\")\n",
    "longer_chromosome = long_seqs[0]\n",
    "shorter_chromosome = long_seqs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae51b79f-aada-4fcc-8aab-71853bf58885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30288\n"
     ]
    }
   ],
   "source": [
    "# Get reads from long sequence\n",
    "seqs = get_reads_from(shorter_chromosome, read_len=250, coverage=10)\n",
    "print(len(seqs))\n",
    "seqs.insert(0, parse_nucleotides(shorter_chromosome, caps=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "423d6258-31a2-47de-9129-96c237168fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building hashmap\n",
      "seq 0\n",
      "seq 3000\n",
      "seq 6000\n",
      "seq 9000\n",
      "seq 12000\n",
      "seq 15000\n",
      "seq 18000\n",
      "seq 21000\n",
      "seq 24000\n",
      "seq 27000\n",
      "seq 30000\n",
      "Getting and fixing maxcounts now\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Get max counts from reads\n",
    "seq_to_investigate = 0\n",
    "str_profile = \"1111110110110101110101011101011111101111\"\n",
    "profile = [int(character) for character in str_profile]\n",
    "k = sum(profile)\n",
    "f = len(profile)\n",
    "\n",
    "# Turn into np arrays for componentwise multiplication\n",
    "profile = np.array(profile)\n",
    "\n",
    "print(\"building hashmap\")\n",
    "starts, ends = {}, {}\n",
    "seqs_kmers = {}\n",
    "for (sequence, j) in zip(seqs, range(len(seqs))):\n",
    "    if j %3000 == 0: print(\"seq \" + str(j))\n",
    "    for i in range(len(sequence) - f):\n",
    "        #if i%500000 == 0:\n",
    "            #print(i)\n",
    "        #parsed_seq = parse_nucleotides(sequence, caps=True)\n",
    "        spaced_kmer = sequence[i:i+f] * profile\n",
    "        spaced_kmer = spaced_kmer[spaced_kmer != 0]\n",
    "        s = ''.join(str(x) for x in spaced_kmer)\n",
    "        seqs_kmers[s] = seqs_kmers.get(s, 0) + 1\n",
    "\n",
    "        if i == 0 or i == len(sequence)-f-1:\n",
    "            solid_kmer = sequence[i:i+f]\n",
    "            s2 = ''.join(str(x) for x in solid_kmer)\n",
    "            addon = 0\n",
    "            if i == 0:\n",
    "                starts[s2] = starts.get(s2, 0) + 1\n",
    "            else: \n",
    "                ends[s2] = ends.get(s2, 0) + 1\n",
    "\n",
    "print(\"Getting and fixing maxcounts now\")\n",
    "# Get maxcounts from counts\n",
    "target = seqs[seq_to_investigate]\n",
    "xpoints = np.array([i for i in range(len(target) - f)])\n",
    "max_counts = []\n",
    "max_count_indices = []\n",
    "for i in range(len(xpoints)):\n",
    "    maxp, argmaxp = get_maxcount(i, seqs_kmers, profile, target)\n",
    "    max_counts.append(maxp)\n",
    "    max_count_indices.append(argmaxp)\n",
    "\n",
    "print(\"done\")\n",
    "# Get correction profile:\n",
    "#start_end_posis = get_correction_profile(target, seqs, f, starts, ends)\n",
    "\n",
    "# Get diff profile:\n",
    "#pre_corr_diff_profile = [max_counts[j] - max_counts[j-1] for j in range(1,len(max_counts))]\n",
    "\n",
    "# Apply correction strategy\n",
    "#ypoints, correction_artifact = correct_counts(max_counts, max_count_indices, target, start_end_posis, seqs, pre_corr_diff_profile.copy(), profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d752c7dc-1d07-44e6-8368-7a2d8563b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./mcProfile_chromo_spaced_short.wig\", \"w\") as file:\n",
    "    file.write(\"track type=wiggle_0\\n\")\n",
    "    file.write(\"variableStep  chrom=chr2\\n\")\n",
    "    for i in range(len(max_counts)):\n",
    "        strline = str(i) + \" \" + str(max_counts[i]) + \"\\n\"\n",
    "        file.write(strline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad4a2752-bb6f-44e2-a2d0-615cfd6ce5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./mcProfile_fixed_chromo_spaced_short.wig\", \"w\") as file:\n",
    "    file.write(\"track type=wiggle_0\\n\")\n",
    "    file.write(\"fixedStep chrom=chr2 start=1 step=1\\n\")\n",
    "    for i in range(len(max_counts)):\n",
    "        strline = str(max_counts[i]) + \"\\n\"\n",
    "        file.write(strline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f58bb25-8bd4-4f77-8015-45974f0ebc93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d63b3-048d-4cee-93e4-a5943665c58c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
